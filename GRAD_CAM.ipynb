{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwPNHnilah7Z",
        "outputId": "9f9ee713-dceb-4d7b-ad60-21209f4f84aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grad-cam==1.5.5 in /usr/local/lib/python3.12/dist-packages (1.5.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (0.24.0+cu126)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (0.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam==1.5.5) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam==1.5.5) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam==1.5.5) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam==1.5.5) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam==1.5.5) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam==1.5.5) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->grad-cam==1.5.5) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->grad-cam==1.5.5) (3.0.3)\n",
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "Pred mask shape: torch.Size([8, 128, 128])\n",
            "Pred mask shape: torch.Size([8, 128, 128])\n",
            "Pred mask shape: torch.Size([8, 128, 128])\n",
            "Pred mask shape: torch.Size([8, 128, 128])\n",
            "Pred mask shape: torch.Size([8, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "!pip install grad-cam==1.5.5\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ACDCDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, crop=True, crop_size=128):\n",
        "        self.root_dir = root_dir\n",
        "        self.files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\".h5\")]\n",
        "        self.transform = transform\n",
        "        self.crop = crop\n",
        "        self.crop_size = crop_size  # final size after cropping (square)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.files[idx]\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            image = np.array(f[\"image\"])\n",
        "            mask  = np.array(f[\"label\"])\n",
        "\n",
        "        # normalize to [0,1]\n",
        "        image = image.astype(np.float32)\n",
        "        image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "\n",
        "        # crop around heart region if enabled\n",
        "        if self.crop and np.any(mask > 0):  # only if mask not empty\n",
        "            coords = np.argwhere(mask > 0)\n",
        "            y_min, x_min = coords.min(axis=0)\n",
        "            y_max, x_max = coords.max(axis=0)\n",
        "\n",
        "            # add padding\n",
        "            pad = 15\n",
        "            y_min = max(y_min - pad, 0)\n",
        "            x_min = max(x_min - pad, 0)\n",
        "            y_max = min(y_max + pad, image.shape[0])\n",
        "            x_max = min(x_max + pad, image.shape[1])\n",
        "\n",
        "            # crop image and mask\n",
        "            image = image[y_min:y_max, x_min:x_max]\n",
        "            mask  = mask[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        # resize/crop to fixed size\n",
        "        if self.crop_size:\n",
        "            from skimage.transform import resize\n",
        "            image = resize(image, (self.crop_size, self.crop_size), preserve_range=True, anti_aliasing=True)\n",
        "            mask  = resize(mask, (self.crop_size, self.crop_size), order=0, preserve_range=True, anti_aliasing=False)\n",
        "\n",
        "        # add channel dim (C,H,W)\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        #mask  = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "        mask  = torch.tensor(mask, dtype=torch.long)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ---------------  # Basic UNet Block----------------\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# -------------------------------\n",
        "# UNet Model\n",
        "# -------------------------------\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=2):\n",
        "        super(UNet, self).__init__()\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool(e1))\n",
        "        e3 = self.enc3(self.pool(e2))\n",
        "        e4 = self.enc4(self.pool(e3))\n",
        "\n",
        "        b = self.bottleneck(self.pool(e4))\n",
        "\n",
        "        d4 = self.up4(b)\n",
        "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
        "\n",
        "        return self.final(d1)\n",
        "\n",
        "#--------------------------------- grad_cam relevent functions ------------\n",
        "# class SegmentationTarget:\n",
        "#       def __init__(self, category, mask_tensor):\n",
        "#           \"\"\"\n",
        "#           category: int, the class index you want to explain (e.g., 1 for LV, 2 for myocardium)\n",
        "#           mask_tensor: torch.Tensor of shape (H, W), region of interest\n",
        "#           \"\"\"\n",
        "#           self.category = category\n",
        "#           self.mask_tensor = mask_tensor\n",
        "\n",
        "#       def __call__(self, model_output):\n",
        "#           # model_output shape: (C, H, W)\n",
        "#           class_map = model_output[self.category, :,  :]\n",
        "#           return (class_map * self.mask_tensor.to(class_map.device)).sum()\n",
        "\n",
        "# class SegmentationTarget:\n",
        "#     def __init__(self, mask_tensor, target_class):\n",
        "#         self.mask_tensor = mask_tensor  # (1, H, W)\n",
        "#         self.target_class = target_class\n",
        "\n",
        "#     def __call__(self, model_output):\n",
        "#         # Keep everything as a tensor\n",
        "#         class_map = model_output[self.target_class, :, :]  # Still a torch tensor\n",
        "#         # Ensure mask is on same device and type\n",
        "#         mask = self.mask_tensor.to(class_map.device).float()\n",
        "#         # Element-wise multiply and sum\n",
        "#         return (class_map * mask).sum()\n",
        "\n",
        "class SegmentationTarget:\n",
        "    def __init__(self, mask_tensor, target_class):\n",
        "        self.mask_tensor = mask_tensor\n",
        "        self.target_class = target_class\n",
        "        # self.batch_idx = batch_idx\n",
        "\n",
        "    def __call__(self, model_output):\n",
        "        # model_output: (B, C, H, W)\n",
        "        class_map = model_output[ self.target_class, :, :]\n",
        "        mask = self.mask_tensor.to(class_map.device).float()\n",
        "        if mask.ndim == 3:\n",
        "            mask = mask.squeeze(0)\n",
        "        return (class_map * mask).sum()\n",
        "\n",
        "def generate_gradcam(model, image, mask, target_class, target_layer):\n",
        "\n",
        "  model.eval()\n",
        "  cam = GradCAM(model=model, target_layers=[target_layer])\n",
        "\n",
        "\n",
        "  targets = [SegmentationTarget(target_class, mask)]\n",
        "  input_tensor = image.to(\"cuda\")   # shape (1, 1, H, W)\n",
        "\n",
        "  grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "  grayscale_cam = grayscale_cam[0, :]   # first image in batch\n",
        "  return grayscale_cam\n",
        "\n",
        "def gradcam_overlap_score(gradcam, gt_mask, class_id=2, threshold=0.4, metric='dice'):\n",
        "    \"\"\"\n",
        "    Compute overlap between Grad-CAM heatmap and a ground-truth region (e.g., myocardium).\n",
        "\n",
        "    Args:\n",
        "        gradcam (ndarray): Grad-CAM heatmap (values in [0, 1]).\n",
        "        gt_mask (ndarray): Ground truth segmentation mask.\n",
        "        class_id (int): Target class label (e.g., 2 for myocardium).\n",
        "        threshold (float): Threshold to binarize Grad-CAM.\n",
        "        metric (str): 'dice' or 'iou'.\n",
        "\n",
        "    Returns:\n",
        "        float: Overlap score.\n",
        "    \"\"\"\n",
        "    gradcam_bin = (gradcam > threshold).astype(np.uint8)\n",
        "    gt_bin = (gt_mask == class_id).astype(np.uint8)\n",
        "\n",
        "    intersection = np.sum(gradcam_bin * gt_bin)\n",
        "    union = np.sum(gradcam_bin) + np.sum(gt_bin)\n",
        "\n",
        "    if metric == 'dice':\n",
        "        return (2.0 * intersection) / (union + 1e-8)\n",
        "    elif metric == 'iou':\n",
        "        union_iou = np.sum((gradcam_bin + gt_bin) > 0)\n",
        "        return intersection / (union_iou + 1e-8)\n",
        "    else:\n",
        "        raise ValueError(\"metric should be 'dice' or 'iou'\")\n",
        "\n",
        "\n",
        "def evaluate_gradcam_for_loader(model, loader, target_layer, class_idx, bin_k=0.2, device='cuda'):\n",
        "  model.eval()\n",
        "  cam = GradCAM(model=model, target_layers=[target_layer])\n",
        "  per_image_scores = []\n",
        "  # optional: collect cams/images for examples\n",
        "  for images, masks in loader:\n",
        "\n",
        "      targets = [ SegmentationTarget(mask_tensor=masks[i], target_class= class_idx)  for i in range(images.shape[0])]\n",
        "\n",
        "      grayscale_cams = cam(input_tensor=images, targets=targets)\n",
        "\n",
        "      # visualization\n",
        "\n",
        "      # for i in range(images.shape[0]):\n",
        "      #     img = images[i].cpu().squeeze().numpy()\n",
        "      #     img = np.stack([img]*3, axis=-1)  # make it 3-channel for visualization\n",
        "      #     cam_image = show_cam_on_image(img, grayscale_cams[i], use_rgb=True)\n",
        "      #     plt.figure()\n",
        "      #     plt.title(f\"Grad-CAM for Image {i}\")\n",
        "      #     plt.imshow(cam_image)\n",
        "      #     plt.axis(\"off\")\n",
        "      #     plt.show()\n",
        "\n",
        "\n",
        "        # images = images.to(device)\n",
        "      masks_np = masks.cpu().numpy()  # (B,H,W)\n",
        "        # # make targets per image so cam returns one heatmap per input\n",
        "        # # (assumes SegmentationTarget callable exists)\n",
        "        # # We'll call cam per-batch but pass per-image targets\n",
        "        # targets = []\n",
        "        # for b in range(images.shape[0]):\n",
        "        #     gt_class_mask = (masks_np[b] == class_idx).astype(np.uint8)\n",
        "        #     targets.append(SegmentationTarget(class_idx, gt_class_mask))\n",
        "        # # get cams: shape (B, Hcam, Wcam)\n",
        "\n",
        "        # grayscale_cams = cam(input_tensor=images, targets=targets)\n",
        "        # # iterate each sample:\n",
        "      for b in range(images.shape[0]):\n",
        "            gcam = grayscale_cams[b]\n",
        "            # upsample if needed\n",
        "            if gcam.shape != masks_np[b].shape:\n",
        "                gcam_t = torch.tensor(gcam).unsqueeze(0).unsqueeze(0)\n",
        "                gcam_t = torch.nn.functional.interpolate(gcam_t, size=masks_np[b].shape, mode='bilinear', align_corners=False)\n",
        "                gcam = gcam_t.squeeze().cpu().numpy()\n",
        "\n",
        "            cam_bin = binarize_cam(gcam, method='topk', k=bin_k)\n",
        "            gt_bin = (masks_np[b] == class_idx).astype(np.uint8)\n",
        "            score = dice_from_masks(cam_bin, gt_bin)\n",
        "            per_image_scores.append(score)\n",
        "\n",
        "            #----------------visualization  -----------\n",
        "            # plt.figure(figsize=(12,4))\n",
        "\n",
        "            # # Original MRI\n",
        "            # plt.subplot(1,3,1)\n",
        "            # plt.imshow(images[b,0].cpu(), cmap='gray')\n",
        "            # plt.title(\"Input MRI\")\n",
        "\n",
        "            # # Ground truth mask\n",
        "            # plt.subplot(1,3,2)\n",
        "            # plt.imshow(masks[b].cpu(), cmap='gray')\n",
        "            # plt.title(\"Ground truth mask\")\n",
        "\n",
        "            # # Grad-CAM heatmap\n",
        "            # plt.subplot(1,3,3)\n",
        "            # plt.imshow(gcam, cmap='jet')\n",
        "            # plt.title(\"Grad-CAM\")\n",
        "\n",
        "            # plt.show()\n",
        "            # input(\"Press Enter to continue...\") # Comment out this line\n",
        "\n",
        "  return np.array(per_image_scores)\n",
        "\n",
        "\n",
        "def binarize_cam(cam, method='topk', k=0.2, thresh=None):\n",
        "    \"\"\"\n",
        "    Convert a Grad-CAM heatmap into a binary mask.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cam : np.ndarray\n",
        "        Grad-CAM heatmap normalized between 0 and 1, shape (H, W)\n",
        "    method : str\n",
        "        'topk' – keep top-k fraction of pixels as 1\n",
        "        'thresh' – use a fixed threshold value\n",
        "    k : float\n",
        "        Fraction (for topk) – e.g. 0.2 keeps the top 20% highest values.\n",
        "    thresh : float\n",
        "        Explicit threshold (for 'thresh' method) between 0 and 1.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    binary_mask : np.ndarray of dtype uint8\n",
        "        Binary map (0 or 1)\n",
        "    \"\"\"\n",
        "    cam = np.clip(cam, 0, 1)  # ensure within [0,1]\n",
        "    if method == 'topk':\n",
        "        flat = cam.flatten()\n",
        "        cutoff = np.quantile(flat, 1 - k)\n",
        "        mask = (cam >= cutoff).astype(np.uint8)\n",
        "    elif method == 'thresh':\n",
        "        t = thresh if thresh is not None else 0.5\n",
        "        mask = (cam >= t).astype(np.uint8)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "    return mask\n",
        "\n",
        "def dice_from_masks(pred_mask, gt_mask, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Compute Dice score between two binary masks.\n",
        "    \"\"\"\n",
        "    pred = pred_mask.astype(bool)\n",
        "    gt   = gt_mask.astype(bool)\n",
        "    inter = np.logical_and(pred, gt).sum()\n",
        "    union = pred.sum() + gt.sum()\n",
        "    if union == 0:\n",
        "        return 1.0  # Or 0.0, depending on convention for empty masks\n",
        "    return (2.0 * inter) / (union + eps)\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/ACDC_preprocessed/ACDC_training_slices\"\n",
        "\n",
        "full_dataset = ACDCDataset(dataset_path)\n",
        "#------------------------------\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "  # Initialize model\n",
        "model = UNet(in_channels=1, out_channels=4).to(device)\n",
        "\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "dice_scores_seed = []\n",
        "per_seed_scores = {}\n",
        "all_seed_stats = []\n",
        "\n",
        "training = 0  #whether the trained model weights are intended to be loaded or the training pahse should be performed\n",
        "\n",
        "target_class=2   #1:RV, 2:myocardium, 3:LV\n",
        "target_layer=model.dec2   #target layer\n",
        "seed=5\n",
        "\n",
        "# results_dir = \"/content/results\"\n",
        "results_dir = \"/content/drive/MyDrive/GRADCAM_Scores_results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "for i in range(seed):\n",
        "  torch.manual_seed(i)\n",
        "  np.random.seed(i)\n",
        "  random.seed(i)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "  # Create DataLoaders\n",
        "  train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "  val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "  # print(f\"Total samples: {len(full_dataset)}\")\n",
        "  # print(f\"Training samples: {len(train_dataset)}\")\n",
        "  # print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "  # -------------------------\n",
        "\n",
        "\n",
        "  if  training:     #if training is not run before\n",
        "\n",
        "  # Loss & optimizer\n",
        "      criterion = nn.CrossEntropyLoss()   # good for segmentation with class labels\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "      num_epochs = 5  # start small for testing\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          model.train()\n",
        "          total_loss = 0\n",
        "          for images, masks in train_loader:\n",
        "              images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "              # Forward\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, masks)\n",
        "\n",
        "              # Backward\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "          avg_loss = total_loss / len(train_loader)\n",
        "          print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "      torch.save(model.state_dict(), \"/content/drive/MyDrive/unet_resnet_acdc.pth\")\n",
        "\n",
        "      print(\"weight saved\")\n",
        "  else:\n",
        "\n",
        "      model.load_state_dict(torch.load(\"/content/drive/MyDrive/unet_resnet_acdc.pth\", map_location=\"cpu\"))\n",
        "\n",
        "  #-------------- validation loop-----------\n",
        "  model.eval()   #evaluation of first epoch of images\n",
        "  with torch.no_grad():\n",
        "      for images, masks in val_loader:\n",
        "          images, masks = images.to(device), masks.to(device)\n",
        "          outputs = model(images)\n",
        "          preds = torch.argmax(outputs, dim=1)  # (B, H, W)\n",
        "          print(\"Pred mask shape:\", preds.shape)\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ---------  dice score for whole dataset  ---------------\n",
        "  # def dice_score_dataset(loader, model, num_classes, device=\"cuda\"):\n",
        "  #     model.eval()\n",
        "  #     total_intersection = torch.zeros(num_classes, device=device)\n",
        "  #     total_union = torch.zeros(num_classes, device=device)\n",
        "\n",
        "  #     with torch.no_grad():\n",
        "  #         for images, masks in loader:\n",
        "  #             images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "  #             outputs = model(images)\n",
        "  #             preds = torch.argmax(outputs, 1)\n",
        "\n",
        "  #             for c in range(num_classes):\n",
        "  #                 pred_c = (preds == c).float()\n",
        "  #                 target_c = (masks == c).float()\n",
        "\n",
        "  #                 total_intersection[c] += (pred_c * target_c).sum()\n",
        "  #                 total_union[c] += pred_c.sum() + target_c.sum()\n",
        "\n",
        "  #     dice_scores = (2. * total_intersection) / (total_union + 1e-8)\n",
        "  #     return dice_scores.cpu().numpy()  # one dice score per class\n",
        "\n",
        "\n",
        "\n",
        "  # val_dice = dice_score_dataset(val_loader, model, num_classes=4)\n",
        "  # print(\"Validation Dice per class:\", val_dice)\n",
        "  # print(\"Mean Dice:\", val_dice.mean()\n",
        "\n",
        "  #-----------  GRAD-CAM EVALUATION   --------------\n",
        "\n",
        "  # import numpy as np\n",
        "  # import torch\n",
        "  # import torch.nn.functional as F\n",
        "  # import pandas as pd\n",
        "  # from tqdm import tqdm\n",
        "  # from pytorch_grad_cam import GradCAM\n",
        "\n",
        "  # # --- Dice and IoU metrics ---\n",
        "  # def binarize_cam(cam, method='topk', k=0.2, thresh=0.3):\n",
        "  #     if method == 'topk':\n",
        "  #         flat = cam.flatten()\n",
        "  #         cutoff = np.percentile(flat, 100*(1-k))\n",
        "  #         mask = (cam >= cutoff).astype(np.uint8)\n",
        "  #     else:\n",
        "  #         mask = (cam >= thresh).astype(np.uint8)\n",
        "  #     return mask\n",
        "\n",
        "  # def dice_from_masks(pred_mask, gt_mask, eps=1e-8):\n",
        "  #     pred = pred_mask.astype(bool)\n",
        "  #     gt   = gt_mask.astype(bool)\n",
        "  #     inter = np.logical_and(pred, gt).sum()\n",
        "  #     union = pred.sum() + gt.sum()\n",
        "  #     if union == 0:\n",
        "  #         return 1.0\n",
        "  #     return (2.0 * inter) / (union + eps)\n",
        "\n",
        "  # def iou_from_masks(pred_mask, gt_mask, eps=1e-8):\n",
        "  #     pred = pred_mask.astype(bool)\n",
        "  #     gt   = gt_mask.astype(bool)\n",
        "  #     inter = np.logical_and(pred, gt).sum()\n",
        "  #     union = np.logical_or(pred, gt).sum()\n",
        "  #     if union == 0:\n",
        "  #         return 1.0\n",
        "  #     return inter / (union + eps)\n",
        "\n",
        "  # # --- Candidate layers from your U-Net ---\n",
        "  # candidates = {\n",
        "  #     'enc3': model.enc3,\n",
        "  #     'enc4': model.enc4,\n",
        "  #     'bottleneck': getattr(model, 'bottleneck', None),\n",
        "  #     'dec1': getattr(model, 'dec1', None),\n",
        "  # }\n",
        "  # candidates = {k: v for k, v in candidates.items() if v is not None}\n",
        "\n",
        "  # # Initialize GradCAM for each candidate layer\n",
        "  # cams = {name: GradCAM(model=model, target_layers=[layer], device='cuda')\n",
        "  #         for name, layer in candidates.items()}\n",
        "\n",
        "  # # --- ACDC class mapping ---\n",
        "  # class_map = {1: \"RV\", 2: \"MYO\", 3: \"LV\"}\n",
        "\n",
        "  # # Store results\n",
        "  # results = []\n",
        "\n",
        "  # model.eval()\n",
        "  # with torch.no_grad():\n",
        "  #     for i, (images, masks) in enumerate(tqdm(val_loader)):\n",
        "  #         images = images.to('cuda')\n",
        "  #         masks  = masks.to('cpu').numpy()  # (B,H,W)\n",
        "  #         B = images.shape[0]\n",
        "\n",
        "  #         for b in range(B):\n",
        "  #             inp = images[b:b+1]   # (1,1,H,W)\n",
        "  #             gt  = masks[b]        # (H,W)\n",
        "\n",
        "  #             for class_idx, class_name in class_map.items():\n",
        "  #                 # ground truth binary mask\n",
        "  #                 gt_class = (gt == class_idx).astype(np.uint8)\n",
        "\n",
        "  #                 for name, cam in cams.items():\n",
        "  #                     # GradCAM heatmap\n",
        "  #                     targets = [SegmentationTarget(class_idx, gt_class)]\n",
        "  #                     grayscale_cam = cam(input_tensor=inp, targets=targets)\n",
        "  #                     gcam = grayscale_cam[0]\n",
        "\n",
        "  #                     # resize CAM to match GT\n",
        "  #                     if gcam.shape != gt.shape:\n",
        "  #                         gcam = torch.tensor(gcam).unsqueeze(0).unsqueeze(0)\n",
        "  #                         gcam = F.interpolate(gcam, size=gt.shape,\n",
        "  #                                              mode='bilinear', align_corners=False).squeeze().cpu().numpy()\n",
        "\n",
        "  #                     # Try multiple binarization strategies\n",
        "  #                     for method, params in [('topk', [0.1, 0.2, 0.3]),\n",
        "  #                                            ('thresh', [0.2, 0.3, 0.5])]:\n",
        "  #                         for p in params:\n",
        "  #                             if method == 'topk':\n",
        "  #                                 cam_mask = binarize_cam(gcam, method='topk', k=p)\n",
        "  #                                 label = f\"top{int(p*100)}\"\n",
        "  #                             else:\n",
        "  #                                 cam_mask = binarize_cam(gcam, method='thresh', thresh=p)\n",
        "  #                                 label = f\"thr{p}\"\n",
        "\n",
        "  #                             d = dice_from_masks(cam_mask, gt_class)\n",
        "  #                             j = iou_from_masks(cam_mask, gt_class)\n",
        "\n",
        "  #                             results.append({\n",
        "  #                                 'sample': i,\n",
        "  #                                 'layer': name,\n",
        "  #                                 'class': class_name,\n",
        "  #                                 'bin_method': label,\n",
        "  #                                 'dice': d,\n",
        "  #                                 'iou': j\n",
        "  #                             })\n",
        "\n",
        "  # # Save results to CSV\n",
        "  # df = pd.DataFrame(results)\n",
        "  # df.to_csv(\"gradcam_layer_comparison.csv\", index=False)\n",
        "\n",
        "  # # Print summary\n",
        "  # summary = df.groupby([\"layer\", \"class\", \"bin_method\"]).mean().reset_index()\n",
        "  # print(summary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #------------  add SE block  ---------------\n",
        "  # class SEBlock(nn.Module):\n",
        "  #     def __init__(self, in_channels, reduction=16):\n",
        "  #         super().__init__()\n",
        "  #         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "  #         self.fc = nn.Sequential(\n",
        "  #             nn.Linear(in_channels, in_channels // reduction),\n",
        "  #             nn.ReLU(inplace=True),\n",
        "  #             nn.Linear(in_channels // reduction, in_channels),\n",
        "  #             nn.Sigmoid()\n",
        "  #         )\n",
        "\n",
        "  #     def forward(self, x):\n",
        "  #         b, c, _, _ = x.size()\n",
        "  #         y = self.avg_pool(x).view(b, c)\n",
        "  #         y = self.fc(y).view(b, c, 1, 1)\n",
        "  #         return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "  # self.enc3 = nn.Sequential(\n",
        "  #     resnet.layer3,\n",
        "  #     SEBlock(256)\n",
        "  # )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-----------------  compute grad cam for each batch of images-----------\n",
        "  # dice_scores = []\n",
        "\n",
        "  # for img, mask in val_loader:\n",
        "  #     output = model(img.to(device))\n",
        "  #     gradcam = generate_gradcam(model, img.to(device), mask, target_class,  target_layer)\n",
        "\n",
        "  #     # gradcam = gradcam.squeeze().cpu().numpy()\n",
        "  #     mask = mask.squeeze().cpu().numpy()\n",
        "\n",
        "  #     score = gradcam_overlap_score(gradcam, mask, class_id=2, threshold=0.4)\n",
        "  #     dice_scores.append(score)\n",
        "\n",
        "  # print(f\"Mean Grad-CAM Dice overlap with myocardium: {np.mean(dice_scores):.3f}\")\n",
        "\n",
        "  # dice_scores_seed.append(np.mean(dice_scores))\n",
        "  # print(i)\n",
        "\n",
        "\n",
        "#  ----------- compute grad cam for each image not each batch\n",
        "\n",
        "  scores = evaluate_gradcam_for_loader(model, val_loader, target_layer=model.dec2, class_idx=2, bin_k=0.2, device='cuda')\n",
        "  per_seed_scores[i] = scores\n",
        "  mean = scores[scores != 0].mean()\n",
        "  std  = scores[scores != 0].std()\n",
        "  n = scores.size\n",
        "  sem = stats.sem(scores) if n>1 else 0.0\n",
        "  ci95 = sem * stats.t.ppf((1+0.95)/2, n-1) if n>1 else 0.0\n",
        "  all_seed_stats.append({'seed':i, 'mean':float(mean), 'std':float(std), 'n':int(n), 'ci95':float(ci95)})\n",
        "  # optionally save per-seed raw scores\n",
        "  pd.DataFrame({'score':scores}).to_csv(os.path.join(results_dir, f'seed_{i}_scores.csv'), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_seed_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aedCvnbveUTX",
        "outputId": "cd90f7bc-4296-45f0-82da-db10f5aecab3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'seed': 0, 'mean': 0.6572327828095725, 'std': 0.15774768597311406, 'n': 383, 'ci95': 0.01966288623565771}, {'seed': 1, 'mean': 0.6590698321415533, 'std': 0.16396609548718916, 'n': 383, 'ci95': 0.02041931488711316}, {'seed': 2, 'mean': 0.6666479441830517, 'std': 0.15875225201626064, 'n': 383, 'ci95': 0.021775022213965992}, {'seed': 3, 'mean': 0.6605974978072324, 'std': 0.15933921004100612, 'n': 383, 'ci95': 0.019306977281830087}, {'seed': 4, 'mean': 0.6511822754756053, 'std': 0.17143677411703928, 'n': 383, 'ci95': 0.02202292087861412}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}